{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e692606d-f18e-482a-b4be-77c4591d958b",
   "metadata": {},
   "source": [
    "# Scaling further with Dask Gateway\n",
    "\n",
    "Dask can be deployed on distributed infrastructure, such as a an HPC system or a cloud computing system. There is a growing ecosystem of Dask deployment projects that faciliate easy deployment and scaling of Dask clusters on a wide variety of computing systems.\n",
    "\n",
    "Within LEAP JupyterHub, we can use the `dask-gateway` to create dask clusters.\n",
    "\n",
    "\n",
    "## Introduction to Dask Gateway\n",
    "\n",
    "Dask Gateway helps you manage Dask clusters for multiple users in a scalable, secure, and resource-efficient way. It's designed to work well in environments like JupyterHub or shared cloud infrastructure.\n",
    "\n",
    "Rather than manually setting up a Dask cluster, Dask Gateway automates the process, letting you spin up resources on-demand without worrying about underlying infrastructure details.\n",
    "\n",
    "\n",
    "\n",
    "## When to Use Dask Gateway\n",
    "\n",
    "Dask Gateway is useful when:\n",
    "\n",
    "- You need to run Dask jobs on a shared cluster.\n",
    "- You want to scale your computation dynamically, particularly in cloud or HPC environments.\n",
    "- You prefer not to manage the underlying infrastructure manually (e.g., node management, worker allocation).\n",
    "\n",
    "## Gateway Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271d018-ccef-4412-b163-3f627df354c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "\n",
    "gateway = Gateway()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf4ac7-6d1a-46d3-9b9e-c4ced5a84af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = gateway.cluster_options()\n",
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c4ffb-7ec9-4766-b93f-bc50c1659a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.new_cluster(options)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c80bc-a130-4cf2-9867-8d329e662952",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35837c-df8f-4477-863a-e75c27061032",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e4f5f-60af-420f-b45c-63be41e04de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "x = da.random.random((20_000, 20_000), chunks=(1000, 1000))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb289c-5375-4dc2-8973-9a82c0458806",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + x.T\n",
    "z = y[::2, 5000:].mean(axis=1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ceaf9e-6fb5-4c53-9b92-433683005571",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fc5e2-4dfd-41ad-822f-b35666572f00",
   "metadata": {},
   "source": [
    "### Scaling our cluster on demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08b772-b437-4e87-83e2-b2f682d93134",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758da55d-80e5-40d3-aad4-fa53eafc650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214fe0fa-3624-49d6-bbba-13bfc48618e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a3c86-1103-4749-926a-e47a81ac6972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b606cf-278d-4f91-a487-65343d97be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    \"gs://cmip6/CMIP6/HighResMIP/MOHC/HadGEM3-GC31-HM/highresSST-present/r1i1p1f1/3hr/tas/gn/v20170831/\", engine=\"zarr\", chunks={}\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fa1d85-ad17-48b3-8100-e922929b4164",
   "metadata": {},
   "source": [
    "Passing `chunks={}` to `open_dataset()` works, but since we didn't tell dask how to split up (or chunk) the array, Dask will defer to the backend (`zarr`) to create chunks for our array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912f8e2-4796-4cc5-acac-277d7cd87458",
   "metadata": {},
   "source": [
    "## Parallel and Lazy computation using `dask.array` with xarray\n",
    "\n",
    "\n",
    "Xarray seamlessly wraps dask so all computation is deferred until explicitly requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bb33c-e4cd-4a21-a1ae-953f94de604b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = ds.tas.mean(['lat', 'lon']).dot(ds.tas.T)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b67354-a14b-4029-9e77-b3a9056e895e",
   "metadata": {},
   "source": [
    "As you can see, `z` contains a dask array. This is true for all xarray built-in operations including subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d1ac62-7588-42c9-adc0-c2646e2aab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.isel(lat=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a8706-8536-48b9-872f-dd3ba56da6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfebfab-836e-48a7-b384-cb15cb65401d",
   "metadata": {},
   "source": [
    "## Other Distributed Systems for Dask\n",
    "\n",
    "While Dask Gateway is a great tool for scaling, there are other ways to run Dask on distributed systems:\n",
    "\n",
    "### HPC\n",
    "\n",
    "#### Dask Jobqueue (https://jobqueue.dask.org/)\n",
    "\n",
    "- `dask_jobqueue.PBSCluster`\n",
    "- `dask_jobqueue.SlurmCluster`\n",
    "- `dask_jobqueue.LSFCluster`\n",
    "- etc.\n",
    "\n",
    "#### Dask MPI (https://mpi.dask.org/)\n",
    "\n",
    "- `dask_mpi.initialize`\n",
    "\n",
    "### Cloud (https://coiled.io)\n",
    "\n",
    "A managed cloud service for Dask that abstracts infrastructure concerns, making scaling even easier. \n",
    "\n",
    "- `coiled.Cluster`\n",
    "\n",
    "\n",
    "#### Dask Kubernetes (https://kubernetes.dask.org/)\n",
    "\n",
    "- `dask_kubernetes.KubeCluster`\n",
    "\n",
    "#### Dask Cloud Provider (https://cloudprovider.dask.org)\n",
    "\n",
    "- `dask_cloudprovider.FargateCluster`\n",
    "- `dask_cloudprovider.ECSCluster`\n",
    "- `dask_cloudprovider.ECSCluster`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fdbbd6-11be-440e-9278-c9ba9751f435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
