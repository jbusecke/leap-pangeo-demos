{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b7e4f-b66d-49c5-8ddd-7c460742878c",
   "metadata": {},
   "source": [
    "# When your server is not enough: Scaling large compute tasks with dask (gateway)\n",
    "\n",
    "\n",
    "This notebook introduces the basics of parallelization, focusing on how Dask can help scale your computations.\n",
    "We will cover:\n",
    "- What parallelization is\n",
    "- Embarrassingly parallel tasks\n",
    "- How Dask integrates with Xarray\n",
    "- Diagnosing common issues when working with Dask\n",
    "\n",
    "\n",
    "\n",
    "## Parallelization with Dask\n",
    "\n",
    "When processing large datasets, a single machine can become a bottleneck. **Parallelization** helps by breaking down a task into smaller, independent tasks that can run simultaneously on multiple cores or nodes.\n",
    "\n",
    "The ideal case is when tasks don't need to communicate with each other. This is referred to as **embarrassingly parallel**. For example, filtering independent chunks of a dataset is an embarrassingly parallel task. Dask is one of the tools that provides parallelization functionality within Python. \n",
    "\n",
    "\n",
    "\n",
    "### What is Dask?\n",
    "\n",
    "\n",
    "Dask is a Python library for general purpose parallelism with a bunch of toolkits built on top. Probably you already have it installed on your computer without you knowing it. \n",
    "\n",
    "**First,...**\n",
    "\n",
    "<img src=\"https://github.com/andersy005/xarray-tutorial/blob/main/images/should-i-use-dask.png?raw=true\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c600b-8fb5-4dfb-aede-d85870fbb9bf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Dask: dynamic task scheduler\n",
    "\n",
    "Dask represents distributed/parallel computations with task graphs, more specifically [directed acyclic graphs](https://en.wikipedia.org/wiki/Directed_acyclic_graph).\n",
    "\n",
    "- A task is a function that you want to call and its corresponding inputs\n",
    "- A task graph is a collection of (1) the functions we want to call + their inputs (2) their dependencies. \n",
    "\n",
    "\n",
    "Directed acyclic graphs are made up of nodes and have a clearly defined start and end, a single traversal path, and no looping \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/andersy005/xarray-tutorial/ffb302785027b19447a75ea58990089e667f8ee7/images/dask-task-stream.gif\">\n",
    "\n",
    "At a very basic level, dask is a dynamic task scheduler. That means you give it a set of things you want to run and it decides where to run them on whatever real hardware you've given it. You can give it a laptop and a 100 functions/tasks you want to run and it will figure out how to run that set of tasks on the laptop. you can give it a cluster of 100 machines and it will hopefully run that set of tasks in much faster. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfafb659-3f6a-4a66-a616-096501ce6f30",
   "metadata": {},
   "source": [
    "### Start Dask Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdf273-6106-460e-873a-6e275b11e606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(threads_per_worker=4, n_workers=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ade118-1ac3-4937-86ae-1d6b7ac153a3",
   "metadata": {},
   "source": [
    "### Basics\n",
    "\n",
    "First let's make some toy functions, `square`, `add`, and `square_root` that sleep for a while to simulate work. We'll then time running these functions normally.\n",
    "\n",
    "In the next section we'll parallelize this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a89f20-ef69-443c-83a8-0a8b17857dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47455322-fa5e-4e64-8d54-b84780fd32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    time.sleep(1)\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    time.sleep(1)\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def square_root(x):\n",
    "    time.sleep(1)\n",
    "    return x ** (1 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493a399-cd4b-4c1d-bedb-12d4a7900e06",
   "metadata": {},
   "source": [
    "We time the execution of this normal code using the `%%time` magic, which is a special function of the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de312450-fd53-4973-88d9-44012ddb8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "x = square(3)\n",
    "y = square(4)\n",
    "z = add(x, y)\n",
    "r = square_root(z)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2232ab3d-7560-45dd-af85-c1acc61f66f8",
   "metadata": {},
   "source": [
    "This takes `~4 seconds` to run because we call each function sequentially, one after the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b5ecc-29ac-4139-ab6d-dbc71fee86fa",
   "metadata": {},
   "source": [
    "Those two `square` calls *could* be called in parallel, because they are totally independent of one-another.\n",
    "\n",
    "We'll transform the `square`, `add`, and `square_root` functions using the `dask.delayed` function. When we call the delayed version by passing the arguments, exactly as before, the original function isn't actually called yet - which is why the cell execution finishes very quickly.\n",
    "Instead, a *delayed object* is made, which keeps track of the function to call and the arguments to pass to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48ce9e-78a2-4e0a-96f7-0292377e15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed_square = dask.delayed(square)\n",
    "delayed_add = dask.delayed(add)\n",
    "delayed_square_root = dask.delayed(square_root)\n",
    "\n",
    "x = delayed_square(3)\n",
    "y = delayed_square(4)\n",
    "z = delayed_add(x, y)\n",
    "r = delayed_square_root(z)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683cef2d-207e-49af-b723-c997bbfad7b2",
   "metadata": {},
   "source": [
    "**This ran immediately, since nothing has really happened yet.** \n",
    "\n",
    "To get the result, call `compute`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8a4af-2f6e-409d-b4e5-d2091dd9a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "r.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ddf34f-c105-4936-b336-d60fe15cdd5c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"admonition alert alert-success\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\"></p>\n",
    "    Notice that this runs faster than the original code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae66892-4490-4b67-a386-f94dc81242ee",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "\n",
    "The `r` object is a lazy `Delayed` object.  This object holds everything we need to compute the final result, including references to all of the functions that are required and their inputs and relationship to one-another.  We can evaluate the result with `.compute()` as above or we can visualize the task graph for this value with `.visualize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d039a8-2658-429d-bac1-aa56df71016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee0c68-4132-489b-a7c5-a309f38c31ec",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Reminder: Task and Task Graphs</p>\n",
    "    <ul>\n",
    "        <li> A task is a function that you want to call and its corresponding inputs. </li>\n",
    "    <li> A task graph is a collection of (1) the functions we want to call + their inputs (2) their dependencies. </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7dd6f3-b2ab-4591-9775-41c6b935614a",
   "metadata": {},
   "source": [
    "Notice that this includes the names of the functions from before, and the logical flow of the outputs of the `square` functions to the inputs of `add` and `square_root`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1ed5a-7fc8-4ac0-8909-f4cba097f822",
   "metadata": {},
   "source": [
    "### Some questions to consider:\n",
    "\n",
    "-  Why did we go from 4s to 3s?  Why weren't we able to parallelize down to 2s?\n",
    "-  What would have happened if the `square`, `add`, and `square_root` functions didn't include the `sleep(1)`?  Would Dask still be able to speed up this code?\n",
    "-  What if we have multiple outputs or also want to get access to x or y?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45775347-0f7e-4882-a5a2-4bc0ce60791a",
   "metadata": {},
   "source": [
    "### Submit many tasks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d0baa-e67e-47c3-b4af-e30b60acfeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for value in range(30):\n",
    "    x = delayed_square(value)\n",
    "    y = delayed_square(value)\n",
    "    z = delayed_add(x, y)\n",
    "    r = delayed_square_root(z)\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67170f6d-6616-4bc4-aa83-a681b654a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = dask.compute(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f72176-bfe2-4c26-a8ad-3e81d6194e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f0fd8-3e39-47f7-8f6c-8bdd928106ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result = dask.compute(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336bebb-7d0b-41ad-9502-1fe690772bff",
   "metadata": {},
   "source": [
    "## Dask Array\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/andersy005/xarray-tutorial/ffb302785027b19447a75ea58990089e667f8ee7/images/Dask Array (Light).png\" width=\"50%\" align=\"right\">\n",
    "Dask array provides a parallel, larger-than-memory, n-dimensional array using blocked algorithms. Simply put: distributed Numpy.\n",
    "\n",
    "*  **Parallel**: Uses all of the cores on your computer\n",
    "*  **Larger-than-memory**:  Lets you work on datasets that are larger than your available memory by breaking up your array into many small pieces, operating on those pieces in an order that minimizes the memory footprint of your computation, and effectively streaming data from disk.\n",
    "*  **Blocked Algorithms**:  Perform large computations by performing many smaller computations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9bbae-c653-4ad8-9f4b-a7781716283b",
   "metadata": {},
   "source": [
    "### Blocked Algorithms\n",
    "\n",
    "A *blocked algorithm* executes on a large dataset by breaking it up into many small blocks/chunks.\n",
    "\n",
    "For example, consider taking the sum of a billion numbers.  We might instead break up the array into 1,000 chunks, each of size 1,000,000, take the sum of each chunk, and then take the sum of the intermediate sums.\n",
    "\n",
    "We achieve the intended result (one sum on one billion numbers) by performing many smaller results (one thousand sums on one million numbers each, followed by another sum of a thousand numbers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c52ebd-2b28-4c8a-9e3d-3d2c1fe7d1c9",
   "metadata": {},
   "source": [
    "## `dask.array` contains these algorithms\n",
    "\n",
    "`dask.array` implements a subset of the NumPy ndarray interface using blocked algorithms, cutting up the large array into many small arrays. This lets us compute on arrays larger than memory using multiple cores. We coordinate these blocked algorithms using Dask graphs. Dask Array's are also lazy, meaning that they do not evaluate until you explicitly ask for a result using the compute method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71245b-ddba-40cb-acbe-519dbd76a864",
   "metadata": {},
   "source": [
    "### Create `dask.array` object\n",
    "\n",
    "If we want to create a 3D NumPy array of random values, we do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2dc75-5b73-4c76-8be0-46e201145406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dd705f-dfba-4d80-9bd1-8803adafe021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape = (600, 200, 200)\n",
    "arr = np.random.random(shape)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96118178-f1b3-450e-85b3-0703e69e25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eaa093-cc0b-4df3-a83f-026eddfe0c8c",
   "metadata": {},
   "source": [
    "Now let's create the same array using Dask's array interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1352c0-fb85-4640-a4d1-96dae10ce897",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = da.random.random(shape, chunks=(300, 100, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605cfc6-4273-4837-976a-72a09aa27702",
   "metadata": {},
   "source": [
    "A chunk size to tell us how to block up our array, like `(300, 100, 200)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddc1161-1a05-4a7e-b777-c7bde1f76d45",
   "metadata": {},
   "source": [
    "<div class=\"admonition alert alert-info\">\n",
    "    <p class=\"admonition-title\" style=\"font-weight:bold\">Specifying Chunks</p>\n",
    "    There are <a href=\"https://docs.dask.org/en/latest/array-chunks.html\">several ways to specify chunks</a>. In this tutorial, we will use a block shape.\n",
    "\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6ad71-62a9-4fd8-85f8-48f1beb378ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d49f6f-2458-405f-a87e-75b3c2e20956",
   "metadata": {},
   "source": [
    "Notice that we just see a symbolic representation of the array, including its `shape`, `dtype`, and `chunksize`. No data has been generated yet. Let's visualize the constructed task graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d741e26-50dc-44e3-a9a3-23e75f76b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe07d8b-8411-4cae-af4f-948f65a6d95e",
   "metadata": {},
   "source": [
    "Our array has four chunks. To generate it, Dask calls `np.random.random` four times and then concatenates this together into one array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee131ef-4676-4920-892b-aed943349d00",
   "metadata": {},
   "source": [
    "### Manipulate `dask.array` object as you would a numpy array\n",
    "\n",
    "\n",
    "Now that we have an `Array` we perform standard numpy-style computations like arithmetic, mathematics, slicing, reductions, etc..\n",
    "\n",
    "The interface is familiar, but the actual work is different. `dask_array.sum()` does not do the same thing as `numpy_array.sum()`.\n",
    "\n",
    "#### What's the difference?\n",
    "\n",
    "`dask_array.sum()` builds an expression of the computation. It does not do the computation yet. `numpy_array.sum()` computes the sum immediately.\n",
    "\n",
    "#### Why the difference?\n",
    "\n",
    "Dask arrays are split into chunks. Each chunk must have computations run on that chunk explicitly. If the desired answer comes from a small slice of the entire dataset, running the computation over all data would be wasteful of CPU and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8d02e-0202-4f0b-b61d-575b0ba734af",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = darr.sum()\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5bad7-0e4c-4f33-ab58-a4140dfbed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b4185-c30f-4d72-b5a8-aa0cc8eedd14",
   "metadata": {},
   "source": [
    "#### Compute result\n",
    "\n",
    "Dask.array objects are lazily evaluated.  Operations like `.sum` build up a graph of blocked tasks to execute.  \n",
    "\n",
    "We ask for the final result with a call to `.compute()`.  This triggers the actual computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b31aa8-3fb5-4dc1-be98-f9089a0d4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cad464-45a7-45e0-a46a-559bd14aa751",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3596f71-021f-43a5-a88b-a959e457c8e5",
   "metadata": {},
   "source": [
    "## Dask and Xarray\n",
    "\n",
    "\n",
    "One of xarray's most powerful features: the ability to wrap dask arrays and allow users to seamlessly execute analysis code in parallel.\n",
    "\n",
    "- xarray DataArrays and Datasets are \"dask collections\" i.e. you can execute top-level dask functions such as `dask.visualize(xarray_object)`\n",
    "- All xarray built-in operations can transparently use dask\n",
    "- xarray provides tools to easily parallelize custom functions across blocks of dask-backed xarray objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757dc5e2-b4bf-4955-8f61-d0da5fe118cc",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First let's set up a `LocalCluster` using `dask.distributed`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb8d31-b3ce-4634-a771-569b31b77c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb92f7-9955-4a67-8242-da4598744526",
   "metadata": {},
   "source": [
    "## Reading data with Dask and Xarray\n",
    "\n",
    "Recall that a dask's array consists of many chunked arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1b222-737c-4181-8031-b02317c6e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr = da.ones((2000, 300), chunks=(200, 50))\n",
    "darr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371f8e08-84ec-4af3-8ada-f68051149ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "darr.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eca894-5db3-489d-a503-8d51ec17f463",
   "metadata": {},
   "source": [
    "To read data as dask arrays with xarray, we need to specify the `chunks` argument to `open_dataset()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72d69d-32ec-4a76-bf06-58bc3b5a52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\n",
    "    \"gs://cmip6/CMIP6/HighResMIP/MOHC/HadGEM3-GC31-HM/highresSST-present/r1i1p1f1/3hr/tas/gn/v20170831/\", engine=\"zarr\", chunks={}\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950381e-2621-445c-a432-e9fe5486a0dd",
   "metadata": {},
   "source": [
    "Passing `chunks={}` to `open_dataset()` works, but since we didn't tell dask how to split up (or chunk) the array, Dask will defer to the backend (`zarr`) to create chunks for our array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5924b-f0b0-4ade-9d3e-276753aa2f92",
   "metadata": {},
   "source": [
    "## Parallel and Lazy computation using `dask.array` with xarray\n",
    "\n",
    "\n",
    "Xarray seamlessly wraps dask so all computation is deferred until explicitly requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c1351-b666-4b59-b672-345a0ec90404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = ds.tas.mean(['lat', 'lon']).dot(ds.tas.T)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e5af06-65c6-4e34-9057-922bbde037b0",
   "metadata": {},
   "source": [
    "As you can see, `z` contains a dask array. This is true for all xarray built-in operations including subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213eabbc-9d1d-4a35-9ac5-7ced8f88ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.isel(lat=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077847d-09cb-481c-85d4-2bd023f9bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e0de8-878d-423c-a07a-b1fb8ce61fd5",
   "metadata": {},
   "source": [
    "### Chunking and Making Dask Behave\n",
    "\n",
    "Chunking is an important concept when dealing with large data. It refers to breaking your dataset into smaller, manageable pieces that can be processed in parallel. However, improper chunking can lead to memory overloads or inefficiencies.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- If chunks are too large, they may not fit in memory.\n",
    "- If chunks are too small, the overhead of managing too many tasks could become a bottleneck.\n",
    "\n",
    "Finding the right balance is critical. Dask's diagnostic tools will help you monitor the memory and adjust chunk sizes as needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b9a2f-42b8-4f75-b4a9-12c57bd3e77d",
   "metadata": {},
   "source": [
    "## Transition to Distributed Systems\n",
    "\n",
    "If your local machine can't handle the workload, it’s time to scale beyond a single server. This is where distributed computing comes into play.\n",
    "\n",
    "In the next notebook, we'll discuss Dask Gateway, a tool to scale your computations across multiple machines effortlessly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a4c70-964a-4667-b399-26e308ea4841",
   "metadata": {},
   "source": [
    "## Resources and references\n",
    "\n",
    "* Reference\n",
    "    *  [Docs](https://dask.org/)\n",
    "    *  [Examples](https://examples.dask.org/)\n",
    "    *  [Code](https://github.com/dask/dask/)\n",
    "    *  [Blog](https://blog.dask.org/)\n",
    "*  Ask for help\n",
    "    *   [`dask`](http://stackoverflow.com/questions/tagged/dask) tag on Stack Overflow, for usage questions\n",
    "    *   [github discussions](https://github.com/dask/dask/discussions) for general, non-bug, discussion, and usage questions\n",
    "    *   [github issues](https://github.com/dask/dask/issues/new) for bug reports and feature requests\n",
    "\n",
    "* Pieces of this notebook are adapted from the following sources\n",
    "  * https://github.com/dask/dask-tutorial/blob/main/03_array.ipynb\n",
    "  * https://github.com/xarray-contrib/xarray-tutorial/blob/master/scipy-tutorial/06_xarray_and_dask.ipynb\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8109606-400a-47d3-8e35-b43bc0888ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
